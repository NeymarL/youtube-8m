{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# In this notebook, we'll show how to explore data in the TFRecord format on a smaller scale. To reach the scalability that TensorFlow/Google Cloud can do, please refer to the code in their github https://github.com/google/youtube-8m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "\n",
    "video_lvl_record = \"traina1.tfrecord\"\n",
    "#frame_lvl_record = \"../input/frame_level/train-1.tfrecord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vid_ids = []\n",
    "labels = []\n",
    "mean_rgb = []\n",
    "mean_audio = []\n",
    "\n",
    "for example in tf.python_io.tf_record_iterator(video_lvl_record):\n",
    "    tf_example = tf.train.Example.FromString(example)\n",
    "\n",
    "    vid_ids.append(tf_example.features.feature['video_id'].bytes_list.value[0].decode(encoding='UTF-8'))\n",
    "    labels.append(tf_example.features.feature['labels'].int64_list.value)\n",
    "    mean_rgb.append(tf_example.features.feature['mean_rgb'].float_list.value)\n",
    "    mean_audio.append(tf_example.features.feature['mean_audio'].float_list.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos in this tfrecord:  1218\n",
      "First video feature length 1024\n",
      "First 20 features of the first youtube video ( a1lWP30U9EU )\n",
      "[0.820950984954834, -0.08375737816095352, -0.3228481709957123, 0.5311046242713928, -0.37270453572273254, 0.3170918822288513, -0.5742282271385193, -0.6536586880683899, -0.3352373242378235, -0.8848564028739929, 0.12176278978586197, -0.7401829957962036, 0.4177038371562958, -0.36411207914352417, 0.700456440448761, 0.06471271067857742, 0.928856611251831, -0.2995685338973999, -0.08016052097082138, -0.2395210862159729]\n"
     ]
    }
   ],
   "source": [
    "print('Number of videos in this tfrecord: ',len(mean_rgb))\n",
    "print('First video feature length',len(mean_rgb[0]))\n",
    "print('First 20 features of the first youtube video (',vid_ids[0],')')\n",
    "print(mean_rgb[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9900146126747131, -0.8069257140159607, -0.5610304474830627, -0.5356910824775696, 0.3517039120197296, 0.8091915249824524, 0.07848692685365677, 1.1496354341506958, -0.31772080063819885, 0.07434988766908646, -0.348662406206131, 1.6425464153289795, -0.6701448559761047, -0.11466110497713089, -0.1431894451379776, -0.04665851965546608, -0.02192247100174427, -0.24342645704746246, -0.3828791677951813, -0.21386386454105377, -0.4283865988254547, -0.7872747778892517, 0.03677177429199219, 1.011734127998352, -0.31591084599494934, -0.065361388027668, -0.994816243648529, 0.02617061324417591, -0.181457057595253, -1.0243788957595825, -0.20326270163059235, -0.33444133400917053, 0.6745653748512268, 0.2861146032810211, 0.7539448142051697, -1.3617199659347534, -1.0062793493270874, 0.8640934824943542, -0.6804874539375305, -0.7529718279838562, -0.42407718300819397, -0.286089688539505, 0.6047528386116028, 0.3712686598300934, 0.21793963015079498, -0.1704249531030655, 0.6775819659233093, 0.028583886101841927, 0.14795471727848053, 0.018241286277770996, -0.9707697033882141, 1.068273663520813, 0.34911826252937317, -0.13301922380924225, -0.1194014623761177, -0.5026809573173523, 0.6306955218315125, -0.019509198144078255, 0.9638133645057678, 0.25491440296173096, 0.7864378094673157, -0.08302999287843704, -0.35495415329933167, 0.724382221698761, 0.6348325610160828, 0.8111738562583923, 0.5609691739082336, -0.7981345057487488, 0.3660111725330353, 0.4347894489765167, 0.280857115983963, -0.5884383320808411, -0.3127218782901764, -0.20059086382389069, -0.42157772183418274, -0.227998748421669, 0.35842660069465637, -0.1861974149942398, 0.11416888982057571, -0.01606166549026966, -0.25333812832832336, -0.785378634929657, -0.39253225922584534, -0.20507265627384186, -1.215113639831543, -0.5861112475395203, 0.6340568661689758, 0.2558624744415283, 0.3436022102832794, 0.4110014736652374, 0.554677426815033, -0.24334026873111725, 0.3016285002231598, -0.3447839319705963, -0.8012372851371765, 0.18992842733860016, 0.4638349115848541, 0.2354358583688736, -0.34392204880714417, 0.10529149323701859, 0.6718935370445251, -0.2535105049610138, -0.6761780381202698, -0.7855510115623474, -0.2076583057641983, -1.1228059530258179, 0.6588791012763977, 0.5790687203407288, 0.11201418191194534, 0.4881400167942047, -0.6854001879692078, -0.4956134855747223, -0.8027024865150452, -0.353488951921463, -0.6017975211143494, -0.3546094000339508, 0.009708642959594727, -0.2011941820383072, 0.38316264748573303, 0.2633608877658844, -0.4684641659259796, -0.296518474817276, -0.15844477713108063, 0.35127297043800354, -0.8280418515205383, 0.2197495847940445, 0.1257181167602539, 0.5914798378944397]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_audio[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/a1Mk0IhI2u4\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x113ffc438>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def play_one_vid(record_name, video_index):\n",
    "    return vid_ids[video_index]\n",
    "    \n",
    "# this worked on my local jupyter notebook, but doesn't show on kaggle kernels:\n",
    "YouTubeVideo(play_one_vid(video_lvl_record, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_audio has length of: \n",
      "[128, 128, 128, 128, 128]\n",
      "mean_rgb has length of: \n",
      "[1024, 1024, 1024, 1024, 1024]\n"
     ]
    }
   ],
   "source": [
    "print('mean_audio has length of: ')\n",
    "print([len(x) for x in mean_audio][:5])\n",
    "print('mean_rgb has length of: ')\n",
    "print([len(x) for x in mean_rgb][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# now, let's read the frame-level data\n",
    "# due to execution time, we're only going to read the first video\n",
    "\n",
    "feat_rgb = []\n",
    "feat_audio = []\n",
    "\n",
    "for example in tf.python_io.tf_record_iterator(frame_lvl_record):        \n",
    "    tf_seq_example = tf.train.SequenceExample.FromString(example)\n",
    "    n_frames = len(tf_seq_example.feature_lists.feature_list['audio'].feature)\n",
    "    sess = tf.InteractiveSession()\n",
    "    rgb_frame = []\n",
    "    audio_frame = []\n",
    "    # iterate through frames\n",
    "    for i in range(n_frames):\n",
    "        rgb_frame.append(tf.cast(tf.decode_raw(\n",
    "                tf_seq_example.feature_lists.feature_list['rgb'].feature[i].bytes_list.value[0],tf.uint8)\n",
    "                       ,tf.float32).eval())\n",
    "        audio_frame.append(tf.cast(tf.decode_raw(\n",
    "                tf_seq_example.feature_lists.feature_list['audio'].feature[i].bytes_list.value[0],tf.uint8)\n",
    "                       ,tf.float32).eval())\n",
    "        \n",
    "        \n",
    "    sess.close()\n",
    "    feat_rgb.append(rgb_frame)\n",
    "    feat_audio.append(audio_frame)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('The first video has %d frames' %len(feat_rgb[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# now let's explore a little on the labels\n",
    "Find the most commonly appeared label in this record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "G=nx.Graph()\n",
    "\n",
    "G.clear()\n",
    "for list_of_nodes in labels:\n",
    "    filtered_nodes = set(list_of_nodes).intersection(set(top_n_labels))  \n",
    "    for node1,node2 in list(combinations(filtered_nodes,2)): \n",
    "        node1_name = label_mapping[node1]\n",
    "        node2_name = label_mapping[node2]\n",
    "        G.add_node(node1_name)\n",
    "        G.add_node(node2_name)\n",
    "        G.add_edge(node1_name, node2_name)\n",
    "\n",
    "nx.draw_networkx(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "colors = plt.cm.rainbow(np.linspace(0, 1, n))\n",
    "mean_rgb_top_n = []\n",
    "labels_for_tsne = []\n",
    "# filtering mean_rgb so it only contains top n labels\n",
    "for idx, list_of_nodes in enumerate(labels):\n",
    "    for node in list_of_nodes:\n",
    "        if node in top_n_labels:\n",
    "            mean_rgb_top_n.append(mean_rgb[idx])\n",
    "            labels_for_tsne.append(node)\n",
    "\n",
    "\n",
    "X_embedded = TSNE(n_components=2, random_state=0).fit_transform(mean_rgb_top_n) \n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "handles = []\n",
    "for indx, color in enumerate(colors):\n",
    "    this_label = top_n_labels[indx]\n",
    "    X_embedded_filtered = X_embedded[np.array([x==this_label for x in labels_for_tsne])]\n",
    "    handles.append(ax.scatter(X_embedded_filtered[:, 0], X_embedded_filtered[:, 1], c=color, marker=\"o\",edgecolor='none'))\n",
    "\n",
    "ax.legend(handles, top_n_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = np.zeros([30,10, 3])\n",
    "a[0][0] = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.slim.nets import vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow as tf\n",
    "import numpy as  np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ExpandDims:0\", shape=(30, 300, 1024, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "image = np.zeros([30, 300, 1024])\n",
    "# image = np.zeros([30, 224, 224])\n",
    "image = tf.convert_to_tensor(image, dtype = tf.float32)\n",
    "image = tf.expand_dims(image, 3)\n",
    "# image = tf.reshape(image, [32, 32])\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'vgg_16/fc8/squeezed:0' shape=(30, 1000) dtype=float32>,\n",
       " OrderedDict([('vgg_16/conv1/conv1_1',\n",
       "               <tf.Tensor 'vgg_16/conv1/conv1_1/Relu:0' shape=(30, 224, 224, 64) dtype=float32>),\n",
       "              ('vgg_16/conv1/conv1_2',\n",
       "               <tf.Tensor 'vgg_16/conv1/conv1_2/Relu:0' shape=(30, 224, 224, 64) dtype=float32>),\n",
       "              ('vgg_16/pool1',\n",
       "               <tf.Tensor 'vgg_16/pool1/MaxPool:0' shape=(30, 112, 112, 64) dtype=float32>),\n",
       "              ('vgg_16/conv2/conv2_1',\n",
       "               <tf.Tensor 'vgg_16/conv2/conv2_1/Relu:0' shape=(30, 112, 112, 128) dtype=float32>),\n",
       "              ('vgg_16/conv2/conv2_2',\n",
       "               <tf.Tensor 'vgg_16/conv2/conv2_2/Relu:0' shape=(30, 112, 112, 128) dtype=float32>),\n",
       "              ('vgg_16/pool2',\n",
       "               <tf.Tensor 'vgg_16/pool2/MaxPool:0' shape=(30, 56, 56, 128) dtype=float32>),\n",
       "              ('vgg_16/conv3/conv3_1',\n",
       "               <tf.Tensor 'vgg_16/conv3/conv3_1/Relu:0' shape=(30, 56, 56, 256) dtype=float32>),\n",
       "              ('vgg_16/conv3/conv3_2',\n",
       "               <tf.Tensor 'vgg_16/conv3/conv3_2/Relu:0' shape=(30, 56, 56, 256) dtype=float32>),\n",
       "              ('vgg_16/conv3/conv3_3',\n",
       "               <tf.Tensor 'vgg_16/conv3/conv3_3/Relu:0' shape=(30, 56, 56, 256) dtype=float32>),\n",
       "              ('vgg_16/pool3',\n",
       "               <tf.Tensor 'vgg_16/pool3/MaxPool:0' shape=(30, 28, 28, 256) dtype=float32>),\n",
       "              ('vgg_16/conv4/conv4_1',\n",
       "               <tf.Tensor 'vgg_16/conv4/conv4_1/Relu:0' shape=(30, 28, 28, 512) dtype=float32>),\n",
       "              ('vgg_16/conv4/conv4_2',\n",
       "               <tf.Tensor 'vgg_16/conv4/conv4_2/Relu:0' shape=(30, 28, 28, 512) dtype=float32>),\n",
       "              ('vgg_16/conv4/conv4_3',\n",
       "               <tf.Tensor 'vgg_16/conv4/conv4_3/Relu:0' shape=(30, 28, 28, 512) dtype=float32>),\n",
       "              ('vgg_16/pool4',\n",
       "               <tf.Tensor 'vgg_16/pool4/MaxPool:0' shape=(30, 14, 14, 512) dtype=float32>),\n",
       "              ('vgg_16/conv5/conv5_1',\n",
       "               <tf.Tensor 'vgg_16/conv5/conv5_1/Relu:0' shape=(30, 14, 14, 512) dtype=float32>),\n",
       "              ('vgg_16/conv5/conv5_2',\n",
       "               <tf.Tensor 'vgg_16/conv5/conv5_2/Relu:0' shape=(30, 14, 14, 512) dtype=float32>),\n",
       "              ('vgg_16/conv5/conv5_3',\n",
       "               <tf.Tensor 'vgg_16/conv5/conv5_3/Relu:0' shape=(30, 14, 14, 512) dtype=float32>),\n",
       "              ('vgg_16/pool5',\n",
       "               <tf.Tensor 'vgg_16/pool5/MaxPool:0' shape=(30, 7, 7, 512) dtype=float32>),\n",
       "              ('vgg_16/fc6',\n",
       "               <tf.Tensor 'vgg_16/fc6/Relu:0' shape=(30, 1, 1, 4096) dtype=float32>),\n",
       "              ('vgg_16/fc7',\n",
       "               <tf.Tensor 'vgg_16/fc7/Relu:0' shape=(30, 1, 1, 4096) dtype=float32>),\n",
       "              ('vgg_16/fc8',\n",
       "               <tf.Tensor 'vgg_16/fc8/squeezed:0' shape=(30, 1000) dtype=float32>)]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.vgg_16(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv_31/Relu:0\", shape=(30, 300, 256, 64), dtype=float32)\n",
      "Tensor(\"MaxPool2D_15/MaxPool:0\", shape=(30, 150, 128, 64), dtype=float32)\n",
      "Tensor(\"Conv_33/Relu:0\", shape=(30, 75, 64, 128), dtype=float32)\n",
      "Tensor(\"MaxPool2D_16/MaxPool:0\", shape=(30, 37, 32, 128), dtype=float32)\n",
      "Tensor(\"Conv_35/Relu:0\", shape=(30, 19, 16, 256), dtype=float32)\n",
      "Tensor(\"MaxPool2D_17/MaxPool:0\", shape=(30, 9, 8, 256), dtype=float32)\n",
      "Tensor(\"Conv_37/Relu:0\", shape=(30, 5, 4, 512), dtype=float32)\n",
      "Tensor(\"fully_connected_9/Relu:0\", shape=(30, 5, 4, 512), dtype=float32)\n",
      "Tensor(\"MaxPool2D_18/MaxPool:0\", shape=(30, 2, 2, 512), dtype=float32)\n",
      "Tensor(\"Conv_39/Relu:0\", shape=(30, 2, 2, 512), dtype=float32)\n",
      "Tensor(\"fully_connected_10/Relu:0\", shape=(30, 2, 2, 512), dtype=float32)\n",
      "Tensor(\"MaxPool2D_19/MaxPool:0\", shape=(30, 1, 1, 512), dtype=float32)\n",
      "Tensor(\"fully_connected_11/Relu:0\", shape=(30, 1, 1, 2048), dtype=float32)\n",
      "Tensor(\"Squeeze_2:0\", shape=(30, 2048), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "net = slim.conv2d(image, 64, [3, 3], stride=[1, 2], normalizer_fn=slim.batch_norm)\n",
    "net = slim.conv2d(net, 64, [3, 3], stride=[1, 2], normalizer_fn=slim.batch_norm)\n",
    "print(net)\n",
    "net = slim.max_pool2d(net, [2, 2])\n",
    "print(net)\n",
    "net = slim.conv2d(net, 128, [3, 3], stride=[2, 2])\n",
    "net = slim.conv2d(net, 128, [3, 3])\n",
    "print(net)\n",
    "net = slim.max_pool2d(net, [2, 2])\n",
    "print(net)\n",
    "net = slim.conv2d(net, 256, [3, 3], stride=[2, 2])\n",
    "net = slim.conv2d(net, 256, [3, 3])\n",
    "print(net)\n",
    "net = slim.max_pool2d(net, [2, 2])\n",
    "print(net)\n",
    "net = slim.conv2d(net, 512, [3, 3], stride=[2, 2])\n",
    "net = slim.conv2d(net, 512, [3, 3])\n",
    "print(net)\n",
    "net = slim.relu(net, 512)\n",
    "print(net)\n",
    "net = slim.max_pool2d(net, [2, 2])\n",
    "print(net)\n",
    "net = slim.conv2d(net, 512, [3, 3])\n",
    "net = slim.conv2d(net, 512, [3, 3])\n",
    "print(net)\n",
    "net = slim.relu(net, 512)\n",
    "print(net)\n",
    "net = slim.max_pool2d(net, [2, 2])\n",
    "print(net)\n",
    "net = slim.fully_connected(net, 2048)\n",
    "print(net)\n",
    "net = tf.squeeze(net, [1, 2])\n",
    "print(net)\n",
    "# net = tf.reshape(net, [-1])\n",
    "# print(net)\n",
    "# net = slim.avg_pool2d(net, [2, 2])\n",
    "# print(net)\n",
    "# net = tf.reshape(net, [-1, 512])\n",
    "# print(net)\n",
    "# net = tf.reduce_sum(net, axis=[0]) / tf.convert_to_tensor(100, dtype = tf.float32)\n",
    "# print(net.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'packed_1:0' shape=(1, 512) dtype=float32>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ndarray([2,512])\n",
    "a = tf.convert_to_tensor(a, dtype = tf.float32)\n",
    "b = []\n",
    "b.append(net)\n",
    "b = tf.convert_to_tensor(b, dtype = tf.float32)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = slim.max_pool2d(net, [2, 2], scope='pool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "denominators:  Tensor(\"Reshape_9:0\", shape=(50, 1024), dtype=float32)\n",
      "Tensor(\"Const_14:0\", shape=(50, 100, 1024), dtype=float32)\n",
      "Tensor(\"Sum_12:0\", shape=(50, 1024), dtype=float32)\n",
      "Tensor(\"truediv_6:0\", shape=(50, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "num_frames = [100 for x in range(batch_size)]\n",
    "image = np.zeros([batch_size, 100, 1024])\n",
    "model_input = tf.convert_to_tensor(image, dtype = tf.float32)\n",
    "num_frames = tf.cast(tf.expand_dims(num_frames, 1), tf.float32)\n",
    "feature_size = model_input.get_shape().as_list()[2]\n",
    "print(feature_size)\n",
    "denominators = tf.reshape(\n",
    "    tf.tile(num_frames, [1, feature_size]), [-1, feature_size])\n",
    "print(\"denominators: \", denominators)\n",
    "avg_pooled = tf.reduce_sum(model_input, axis=[1]) / denominators\n",
    "print(model_input)\n",
    "print(tf.reduce_sum(model_input, axis=[1]))\n",
    "print(avg_pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_12:0' shape=(2,) dtype=float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(np.zeros([2]), dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_16:0' shape=(1,) dtype=float32>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor([1], dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"pool8/MaxPool:0\", shape=(30, 1, 1, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.MultiRNNCell object at 0x10e368ba8>\n"
     ]
    }
   ],
   "source": [
    "number_of_layers = 2\n",
    "lstm_size = 1024\n",
    "\n",
    "stacked_lstm = tf.contrib.rnn.MultiRNNCell(\n",
    "        [\n",
    "            tf.contrib.rnn.BasicLSTMCell(\n",
    "                lstm_size, forget_bias=1.0)\n",
    "            for _ in range(number_of_layers)\n",
    "            ])\n",
    "print(stacked_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_2:0\", shape=(128, 300, 1, 1, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "minput = np.zeros([128, 300, 1, 1, 1024])\n",
    "minput = tf.convert_to_tensor(minput, dtype = tf.float32)\n",
    "print(minput)\n",
    "num_frames = [300 for x in range(128)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/transpose:0\", shape=(128, 300, 1024), dtype=float32)\n",
      "(LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 1024) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 1024) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_4:0' shape=(?, 1024) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_5:0' shape=(?, 1024) dtype=float32>))\n",
      "------------------\n",
      "Tensor(\"rnn/while/Exit_5:0\", shape=(?, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(outputs)\n",
    "print(state)\n",
    "print('------------------')\n",
    "print(state[-1].h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_4:0' shape=(?, 1024) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_5:0' shape=(?, 1024) dtype=float32>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'unstack_7:0' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:1' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:2' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:3' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:4' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:5' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:6' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:7' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:8' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:9' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:10' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:11' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:12' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:13' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:14' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:15' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:16' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:17' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:18' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:19' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:20' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:21' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:22' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:23' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:24' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:25' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:26' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:27' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:28' shape=(128, 32, 32, 1) dtype=float32>, <tf.Tensor 'unstack_7:29' shape=(128, 32, 32, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "max_frame = 30\n",
    "feature_size = 1024\n",
    "image = np.zeros([batch_size, max_frame, feature_size])\n",
    "image = tf.convert_to_tensor(image, dtype = tf.float32)\n",
    "image = tf.reshape(image, [-1, max_frame, 32, 32])\n",
    "image = tf.expand_dims(image, 4)\n",
    "image = tf.unstack(image, max_frame, 1)\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool2D_1112/MaxPool:0\", shape=(128, 16, 16, 32), dtype=float32)\n",
      "Tensor(\"MaxPool2D_1113/MaxPool:0\", shape=(128, 8, 8, 64), dtype=float32)\n",
      "Tensor(\"MaxPool2D_1114/MaxPool:0\", shape=(128, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"MaxPool2D_1115/MaxPool:0\", shape=(128, 2, 2, 256), dtype=float32)\n",
      "Tensor(\"MaxPool2D_1116/MaxPool:0\", shape=(128, 1, 1, 256), dtype=float32)\n",
      "Tensor(\"Squeeze_96:0\", shape=(128, 256), dtype=float32)\n",
      "Tensor(\"stack_1:0\", shape=(128, 30, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "network = []\n",
    "for img in image:\n",
    "    net = slim.conv2d(img, 32, [3, 3])\n",
    "    net = slim.relu(net, 32)\n",
    "    net = slim.max_pool2d(net, [2, 2])\n",
    "    if i == 0:\n",
    "        print(net)\n",
    "    net = slim.conv2d(net, 64, [3, 3])\n",
    "    net = slim.relu(net, 64)\n",
    "    net = slim.max_pool2d(net, [2, 2])\n",
    "    if i == 0:\n",
    "        print(net)\n",
    "    net = slim.conv2d(net, 128, [3, 3])\n",
    "    net = slim.relu(net, 128)\n",
    "    net = slim.max_pool2d(net, [2, 2])\n",
    "    if i == 0:\n",
    "        print(net)\n",
    "    net = slim.conv2d(net, 256, [3, 3])\n",
    "    net = slim.relu(net, 256)\n",
    "    net = slim.max_pool2d(net, [2, 2])\n",
    "    if i == 0:\n",
    "        print(net)\n",
    "    net = slim.conv2d(net, 256, [3, 3])\n",
    "    net = slim.relu(net, 256)\n",
    "    net = slim.max_pool2d(net, [2, 2])\n",
    "    if i == 0:\n",
    "        print(net)\n",
    "    net = tf.squeeze(net, [1, 2])\n",
    "    if i == 0:\n",
    "        print(net)\n",
    "    i = i + 1\n",
    "    network.append(net)\n",
    "network = tf.stack(network, 1)\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow as tf\n",
    "import numpy as  np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RCNNCell(tf.contrib.rnn.BasicLSTMCell):\n",
    "    def __init__(self, num_units, forget_bias=1.0, input_size=None, state_is_tuple=True, activation=tf.tanh):\n",
    "        super().__init__(num_units, forget_bias, input_size, state_is_tuple, activation)\n",
    "        self.num_units = num_units\n",
    "        self.forget_bias = forget_bias\n",
    "        self.input_size = input_size\n",
    "        self.state_is_tuple = state_is_tuple\n",
    "        self.activation = activation\n",
    "        \n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        print(inputs)\n",
    "        inputs = tf.reshape(inputs, [-1, 32, 32])\n",
    "        inputs = tf.expand_dims(inputs, 3)\n",
    "        print(inputs)\n",
    "        net = slim.conv2d(inputs, 32, [3, 3])\n",
    "        net = slim.relu(net, 32)\n",
    "        net = slim.max_pool2d(net, [2, 2])\n",
    "        print(net)\n",
    "        net = slim.conv2d(net, 64, [3, 3])\n",
    "        net = slim.relu(net, 64)\n",
    "        net = slim.max_pool2d(net, [2, 2])\n",
    "        print(net)\n",
    "        net = slim.conv2d(net, 128, [3, 3])\n",
    "        net = slim.relu(net, 128)\n",
    "        net = slim.max_pool2d(net, [2, 2])\n",
    "        print(net)\n",
    "        net = slim.conv2d(net, 256, [3, 3])\n",
    "        net = slim.relu(net, 256)\n",
    "        net = slim.max_pool2d(net, [2, 2])\n",
    "        print(net)\n",
    "        net = slim.conv2d(net, 256, [3, 3])\n",
    "        net = slim.relu(net, 256)\n",
    "        net = slim.max_pool2d(net, [2, 2])\n",
    "        print(net)\n",
    "        net = tf.squeeze(net, [1, 2])\n",
    "        print(net)\n",
    "        return super().__call__(net, state, scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.MultiRNNCell object at 0x1222d7fd0>\n"
     ]
    }
   ],
   "source": [
    "number_of_layers = 1\n",
    "lstm_size = 1024\n",
    "\n",
    "stacked_lstm = tf.contrib.rnn.MultiRNNCell(\n",
    "        [\n",
    "            RCNNCell(lstm_size, forget_bias=1.0)\n",
    "            for _ in range(number_of_layers)\n",
    "        ])\n",
    "print(stacked_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(128, 300, 1024), dtype=float32)\n",
      "Tensor(\"rnn/while/TensorArrayReadV3:0\", shape=(128, 1024), dtype=float32)\n",
      "Tensor(\"rnn/while/multi_rnn_cell/cell_0/ExpandDims:0\", shape=(128, 32, 32, 1), dtype=float32)\n",
      "Tensor(\"rnn/while/multi_rnn_cell/cell_0/MaxPool2D/MaxPool:0\", shape=(128, 16, 16, 32), dtype=float32)\n",
      "Tensor(\"rnn/while/multi_rnn_cell/cell_0/MaxPool2D_1/MaxPool:0\", shape=(128, 8, 8, 64), dtype=float32)\n",
      "Tensor(\"rnn/while/multi_rnn_cell/cell_0/MaxPool2D_2/MaxPool:0\", shape=(128, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"rnn/while/multi_rnn_cell/cell_0/MaxPool2D_3/MaxPool:0\", shape=(128, 2, 2, 256), dtype=float32)\n",
      "Tensor(\"rnn/while/multi_rnn_cell/cell_0/MaxPool2D_4/MaxPool:0\", shape=(128, 1, 1, 256), dtype=float32)\n",
      "Tensor(\"rnn/while/multi_rnn_cell/cell_0/Squeeze:0\", shape=(128, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model_input = np.zeros([128, 300, 1024])\n",
    "model_input = tf.convert_to_tensor(model_input, dtype = tf.float32)\n",
    "print(model_input)\n",
    "outputs, state = tf.nn.dynamic_rnn(stacked_lstm, model_input, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/transpose:0\", shape=(128, 300, 1024), dtype=float32)\n",
      "Tensor(\"rnn/while/Exit_3:0\", shape=(?, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(outputs)\n",
    "print(state[0].h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
